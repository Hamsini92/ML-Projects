{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-AQksrzMCVZ"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lf-3oIZMfTx"
      },
      "source": [
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVm8L2-lNord"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cLThAaQOt8A",
        "outputId": "c0c251d0-81b7-4ba3-aada-cefeef17e5c5"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163779\n",
            "Total Vocab:  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcoZ_6llO35s",
        "outputId": "85601cfb-ac37-441c-c9a4-9295a936e929"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ-l1eKFPZHe"
      },
      "source": [
        "...\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdIcq2eIPjIw"
      },
      "source": [
        "...\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5wslWXLT12U"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrumOCv_UHkF",
        "outputId": "9de4dfbd-a683-4edc-9445-e8ff0f163464"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1279/1279 [==============================] - 52s 36ms/step - loss: 2.9878\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98784, saving model to weights-improvement-01-2.9878.hdf5\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.7985\n",
            "\n",
            "Epoch 00002: loss improved from 2.98784 to 2.79853, saving model to weights-improvement-02-2.7985.hdf5\n",
            "Epoch 3/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.7143\n",
            "\n",
            "Epoch 00003: loss improved from 2.79853 to 2.71433, saving model to weights-improvement-03-2.7143.hdf5\n",
            "Epoch 4/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.6449\n",
            "\n",
            "Epoch 00004: loss improved from 2.71433 to 2.64495, saving model to weights-improvement-04-2.6449.hdf5\n",
            "Epoch 5/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.5872\n",
            "\n",
            "Epoch 00005: loss improved from 2.64495 to 2.58721, saving model to weights-improvement-05-2.5872.hdf5\n",
            "Epoch 6/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.5316\n",
            "\n",
            "Epoch 00006: loss improved from 2.58721 to 2.53158, saving model to weights-improvement-06-2.5316.hdf5\n",
            "Epoch 7/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.4783\n",
            "\n",
            "Epoch 00007: loss improved from 2.53158 to 2.47832, saving model to weights-improvement-07-2.4783.hdf5\n",
            "Epoch 8/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.4290\n",
            "\n",
            "Epoch 00008: loss improved from 2.47832 to 2.42905, saving model to weights-improvement-08-2.4290.hdf5\n",
            "Epoch 9/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.3856\n",
            "\n",
            "Epoch 00009: loss improved from 2.42905 to 2.38559, saving model to weights-improvement-09-2.3856.hdf5\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.3443\n",
            "\n",
            "Epoch 00010: loss improved from 2.38559 to 2.34431, saving model to weights-improvement-10-2.3443.hdf5\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.3047\n",
            "\n",
            "Epoch 00011: loss improved from 2.34431 to 2.30471, saving model to weights-improvement-11-2.3047.hdf5\n",
            "Epoch 12/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.2686\n",
            "\n",
            "Epoch 00012: loss improved from 2.30471 to 2.26857, saving model to weights-improvement-12-2.2686.hdf5\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.2328\n",
            "\n",
            "Epoch 00013: loss improved from 2.26857 to 2.23278, saving model to weights-improvement-13-2.2328.hdf5\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - 45s 36ms/step - loss: 2.2005\n",
            "\n",
            "Epoch 00014: loss improved from 2.23278 to 2.20047, saving model to weights-improvement-14-2.2005.hdf5\n",
            "Epoch 15/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.1686\n",
            "\n",
            "Epoch 00015: loss improved from 2.20047 to 2.16865, saving model to weights-improvement-15-2.1686.hdf5\n",
            "Epoch 16/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.1403\n",
            "\n",
            "Epoch 00016: loss improved from 2.16865 to 2.14026, saving model to weights-improvement-16-2.1403.hdf5\n",
            "Epoch 17/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.1111\n",
            "\n",
            "Epoch 00017: loss improved from 2.14026 to 2.11107, saving model to weights-improvement-17-2.1111.hdf5\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.0833\n",
            "\n",
            "Epoch 00018: loss improved from 2.11107 to 2.08335, saving model to weights-improvement-18-2.0833.hdf5\n",
            "Epoch 19/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.0595\n",
            "\n",
            "Epoch 00019: loss improved from 2.08335 to 2.05947, saving model to weights-improvement-19-2.0595.hdf5\n",
            "Epoch 20/20\n",
            "1279/1279 [==============================] - 45s 35ms/step - loss: 2.0338\n",
            "\n",
            "Epoch 00020: loss improved from 2.05947 to 2.03384, saving model to weights-improvement-20-2.0338.hdf5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5602e3d90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAQi_-9xZt_I",
        "outputId": "3f3025bd-b80f-425d-fdf5-8de2b7e4ae05"
      },
      "source": [
        "# pick a random seed\n",
        "import sys\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "undation. \n",
            "     yhu ary orotede tfth the priject gutenberg-tm electronic works on phmeic to toe troject gutenberg-tm electronic works on phoeiction and toe tooe tf the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on aryoliattent oo pemuie ar the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on aryoliattent oo pemuie ar the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on aryoliattent oo pemuie ar the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on aryoliattent oo pemuie ar the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on aryoliattent oo pemuie ar the pooject gutenberg-tm electronic works on pooeict gutenberg-tm electronic works on pooeict gutenberg-tm elect\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}